---
title: "Assignment 2: Neural Network"
output:
  html_document:
    df_print: paged
---

<h3>Prepare the correct language settings for the R-Environment</h3> 
<p>E.g. german console output may lead to issues. Default should be english.</p>
```{r}
# Sys.setlocale("LC_ALL","English")
# Sys.setenv(LANG = "en_US.UTF-8")
# Sys.setlocale("LC_MESSAGES", 'en_GB.UTF-8')
# 
# ## Check if the settings are correct. It should look like:
# ## [1] "LC_COLLATE=English_United States.1252;LC_CTYPE=English_United States.1252;LC_MONETARY=English_United States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252"
# Sys.getlocale()
# 
```


<h3>Install and Load Libraries</h3>
```{r}
libraries_used <- c("keras", "lime", "tidyquant", "rsample", "recipes", "yardstick", "corrr", "caret")

libraries_missing <- libraries_used[!(libraries_used %in% installed.packages()[,"Package"])]
if(length(libraries_missing)) install.packages(libraries_missing)

# Load libraries
library(keras)
library(lime)
library(tidyquant)
library(rsample)
library(recipes)
library(yardstick)
library(corrr)
library(caret)

set.seed(1)
```

<h3>Load Datasets</h3>
```{r}
train_frame <- read.csv("regression_train_loan.csv")
test_frame <- read.csv("loan_eval.csv")
```

<h3>Get meta information and output it</h3>
```{r}
meta_df <- funModeling::df_status( train_frame, print_results = FALSE )

knitr::kable(meta_df)
```

<h3>Get amount and percentage of unique and output the table</h3>
```{r}
meta_df_percent <- meta_df %>% mutate(uniq_rat = unique / nrow(train_frame))
meta_df_percent %>% select(variable, unique, uniq_rat) %>% mutate(unique = unique, uniq_rat = scales::percent(uniq_rat)) %>% knitr::kable()
```

<h3>Output a table with amount of unique, N/A, and zero values</h3>
```{r}
meta_df %>% select(variable, p_zeros, p_na, unique) %>% knitr::kable()
```

<h3>Remove columns deemed unfit for modeling</h3>
<p>All columns with more than 70% missing values are deemed to be unhelpful in modeling and exploration, as well as certain features</p>
```{r}
vars_to_remove <- c("annual_inc_joint", "dti_joint", "policy_code", "id", "member_id",
                    "emp_title", "url", "desc", "title", "open_acc_6m", "open_il_6m", 
                    "open_il_12m", "open_il_24m", "mths_since_rcnt_il", "total_bal_il", 
                    "il_util", "open_rv_12m", "open_rv_24m", "max_bal_bc", "all_util",
                    "total_rev_hi_lim", "inq_fi", "total_cu_tl", "inq_last_12m",
                    "verification_status_joint", "next_pymnt_d", "sub_grade", "X", "zip_code", "application_type")

train_frame <- train_frame %>% select(-one_of(vars_to_remove))
test_frame <- test_frame %>% select(-one_of(vars_to_remove))
```

<h3>Convert date attributes</h3>
```{r}
chr_to_date_vars <-  c("issue_d", "last_pymnt_d", "last_credit_pull_d", "earliest_cr_line")
convert_date <- function(x){
  as.Date(paste0("01-", x), format = "%d-%b-%Y")
}

train_frame <- train_frame %>% mutate_at(.funs = list(convert_date), .vars = chr_to_date_vars)
test_frame <- test_frame %>% mutate_at(.funs = list(convert_date), .vars = chr_to_date_vars)
```

<h3>Output numerical vars</h3>
```{r}
num_vars <-  train_frame %>%  sapply(is.numeric) %>%  which() %>% names()

meta_df <- funModeling::df_status(train_frame, print_results = FALSE) %>%
  select(variable, p_zeros, p_na, unique) %>%
  filter_(~ variable %in% num_vars) %>%
  knitr::kable()

```

<h3>Correlation plot</h3> 
<p>First step to get an overview of potential collinearities. Failing to identify multicollinearity could result in misleading interpretations of the results.</p>
```{r}
corrplot::corrplot(cor(train_frame[, num_vars], use = "complete.obs"), 
                   method = "pie", type = "upper",tl.cex = 0.45)
```

<h3>Recreate meta table</h3>
```{r}
meta_df <- funModeling::df_status( train_frame, print_results = FALSE )
meta_df %>% select(variable, p_zeros, p_na, unique) %>% knitr::kable()
```

<h3>Display highly correlated variables</h3> 
<p>We want to identify collinearities which could affect our regression model. A Cut-off at 0.8 is applied as suggest by Berry & Feldman, 1985: Multiple Regression in Practice (Quantitative Applications in the Social Sciences)</p>

```{r}
caret::findCorrelation(cor(train_frame[, num_vars], use = "complete.obs"), names = TRUE, cutoff = .8)
```

<h3>Remove highly correlated variables to avoid the interference of collinearity in our model</h3>
<p>Multicollinearity arises when at least two highly correlated predictors are assessed simultaneously in a regression model.</p>
```{r}
vars_to_remove <- 
  c("loan_amnt", "funded_amnt", "funded_amnt_inv", "total_pymnt",
    "total_pymnt_inv", "out_prncp", "collection_recovery_fee")

train_frame <- train_frame %>% select(-one_of(vars_to_remove))
test_frame <- test_frame %>% select(-one_of(vars_to_remove))

```

<h3>Recreate meta table</h3>
```{r}
meta_df <- funModeling::df_status( train_frame, print_results = FALSE )
meta_df %>% select(variable, p_zeros, p_na, unique) %>% knitr::kable()
```

<h3>Set vars from N/A to zero</h3>
```{r}
na_to_zero_vars <- c("mths_since_last_delinq", "mths_since_last_record", "mths_since_last_major_derog")

train_frame <- train_frame %>% mutate_at(.vars = na_to_zero_vars, .funs = funs(replace(., is.na(.), 0)))
test_frame <- test_frame %>% mutate_at(.vars = na_to_zero_vars, .funs = funs(replace(., is.na(.), 0)))
```

<h3>Set vars from N/A to -99</h3>
```{r}
na_to_negative_ninety_nine <- c("revol_util", "collections_12_mths_ex_med", "tot_coll_amt", "tot_cur_bal")

train_frame <- train_frame %>% mutate_at(.vars = na_to_negative_ninety_nine, .funs = funs(replace(., is.na(.), -99)))
test_frame <- test_frame %>% mutate_at(.vars = na_to_negative_ninety_nine, .funs = funs(replace(., is.na(.), -99)))
```

<h3>Remove rows where date columns contain N/A values</h3>
```{r}
train_frame <- train_frame[complete.cases(train_frame), ]
test_frame <- test_frame[complete.cases(test_frame), ]
```

<h3>Remove all rows where loan status is "Current" + rename all loan_status fields where the value is not "Fully Paid"</h3>
```{r}
train_frame <- subset(train_frame, loan_status != "Current") 
train_frame$loan_status[train_frame$loan_status != "Fully Paid"] <- "DEFAULTED"

test_frame <- subset(test_frame, loan_status != "Current") 
test_frame$loan_status[test_frame$loan_status != "Fully Paid"] <- "DEFAULTED"
```

<h3>Convert "term" column to number</h3>
```{r}
train_frame$term <- as.numeric(gsub( ".*([0-9]+).*", "\\1", train_frame$term ))

test_frame$term <- as.numeric(gsub( ".*([0-9]+).*", "\\1", test_frame$term ))
```

<h3>Convert "emp_length" to numeric values</h3>
```{r}
train_frame$emp_length[train_frame$emp_length == "n/a"] <- 99
train_frame$emp_length[train_frame$emp_length == "< 1 year"] <- 0
train_frame$emp_length <- as.numeric(gsub( "([0-9]+).*", "\\1", train_frame$emp_length ))

test_frame$emp_length[test_frame$emp_length == "n/a"] <- 99
test_frame$emp_length[test_frame$emp_length == "< 1 year"] <- 0
test_frame$emp_length <- as.numeric(gsub( "([0-9]+).*", "\\1", test_frame$emp_length ))
```

<h3>Data preprocessing</h3>

<p>
The following steps are executed:

<ul>
<li>Remove near-zero variance predictors. These predictors can interfere with our model training using cross-validations. We want to remove variables with a high frequency ratio and a high percentage of unique values.</li>

<li>Convert date predictors into factors/numeric variables and remove the date predictors afterwards</li>

<li>Create dummy variables of nominal predictors.</li>

<li>Normalize numeric data to have a standard deviation of one and a mean of zero</li>
</ul>
</p>
```{r}
recipe_obj <- recipe( loan_status ~ ., data = train_frame ) %>%
  step_nzv(all_predictors()) %>%
  step_date( has_type( match = "date" ) ) %>%
  step_rm( has_type( match = "date" ) ) %>%
  step_dummy( all_nominal(), -all_outcomes() ) %>%
  step_normalize( all_predictors() ) %>%
  prep()

x_train_tbl <- bake(recipe_obj, new_data = train_frame) %>% select(-loan_status)
x_test_tbl <- bake(recipe_obj, new_data = test_frame) %>% select(-loan_status)

y_train_vec <- ifelse(pull(train_frame, loan_status) == "DEFAULTED", 1, 0)
y_test_vec <- ifelse(pull(test_frame, loan_status) == "DEFAULTED", 1, 0)
```

<h3>Build the neural network</h3>
```{r}
# Building our Artificial Neural Network
model_keras <- keras_model_sequential() %>% 
  
  # First hidden layer
  layer_dense(
    units              = 16, 
    kernel_initializer = "uniform", 
    activation         = "relu", 
    input_shape        = ncol(x_train_tbl)) %>% 
  
  # Dropout to prevent overfitting
  layer_dropout(rate = 0.1) %>%
  
  # Second hidden layer
  layer_dense(
    units              = 16, 
    kernel_initializer = "uniform", 
    activation         = "relu") %>% 
  
  # Dropout to prevent overfitting
  layer_dropout(rate = 0.1) %>%
  
  # Output layer
  layer_dense(
    units              = 1, 
    kernel_initializer = "uniform", 
    activation         = "sigmoid") %>% 
  
  # Compile ANN
  compile(
    optimizer = 'adam',
    loss      = 'binary_crossentropy',
    metrics   = c('accuracy')
  )

model_keras 
```

<h3>Fit the neural network with the training data</h3>
```{r}
# Fit the keras model to the training data
history <- fit(
  object           = model_keras, 
  x                = as.matrix(x_train_tbl), 
  y                = y_train_vec,
  batch_size       = 50, 
  epochs           = 35,
  validation_split = 0.30
)

print(history)
```
<h3>Plot the results of the training</h3>
```{r}
plot(history) 
```

<h3>Validate the model using the test data (output estimates)</h3>
```{r}
# Predicted Class
yhat_keras_class_vec <- predict_classes(object = model_keras, x = as.matrix(x_test_tbl)) %>%
    as.vector()

# Predicted Class Probability
yhat_keras_prob_vec  <- predict_proba(object = model_keras, x = as.matrix(x_test_tbl)) %>%
    as.vector()

# Format test data and predictions for yardstick metrics
estimates_keras_tbl <- tibble(
  truth      = as.factor(y_test_vec) %>% forcats::fct_recode(yes = "1", no = "0"),
  estimate   = as.factor(yhat_keras_class_vec) %>% forcats::fct_recode(yes = "1", no = "0"),
  class_prob = yhat_keras_prob_vec
)

estimates_keras_tbl
```

<h3>Confusion Matrix</h3>
```{r}
options(yardstick.event_first = FALSE)

estimates_keras_tbl %>% conf_mat(truth, estimate)
```

<h3>Accuracy</h3>
```{r}
estimates_keras_tbl %>% metrics(truth, estimate)
```

<h3>AUC</h3>
```{r}
estimates_keras_tbl %>% roc_auc(truth, class_prob)
```

<h3>F1-Statistic</h3>
```{r}
estimates_keras_tbl %>% f_meas(truth, estimate, beta = 1)
```

<h3>Export the required data to the filesystem</h3>
```{r}
keras::save_model_hdf5(model_keras, "network.nn")
write.csv(x_train_tbl, "nn_train.csv", row.names = TRUE)
write.csv(x_test_tbl, "nn_test.csv", row.names = TRUE)
```