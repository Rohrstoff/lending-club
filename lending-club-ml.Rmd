---
title: "R Notebook"
output: html_notebook
---

define used libraries
```{r}
libraries_used <- c("lazyeval", "readr","plyr" ,"dplyr", "readxl", "ggplot2", 
    "funModeling", "scales", "tidyverse", "corrplot", "GGally", "caret",
    "rpart", "randomForest", "pROC", "gbm", "choroplethr", "choroplethrMaps",
    "microbenchmark", "doParallel", "e1071")
```

check missing libraries and install them

```{r}
libraries_missing <- libraries_used[!(libraries_used %in% installed.packages()[,"Package"])]
if(length(libraries_missing)) install.packages(libraries_missing)
```

use dplyr
```{r}
library(dplyr)
```

load dataset
```{r}
df <- read.csv("regression_train_loan.csv")
```

get unique values of loan_status
```{r}
library( data.table )
setDT( df )[ , 100 * .N / nrow( df ), by = pymnt_plan ]
```


get meta information and output it
```{r}
meta_df <- funModeling::df_status( df, print_results = FALSE )

knitr::kable(meta_df)
```

get amount and percentage of unique and output the table
```{r}
meta_df_p <- meta_df %>% mutate(uniq_rat = unique / nrow(df))
meta_df_p %>% select(variable, unique, uniq_rat) %>% mutate(unique = unique, uniq_rat = scales::percent(uniq_rat)) %>% knitr::kable()
```

convert date attributes
```{r}
chr_to_date_vars <-  c("issue_d", "last_pymnt_d", "last_credit_pull_d", "next_pymnt_d", "earliest_cr_line", "next_pymnt_d")
convert_date <- function(x){
  as.Date(paste0("01-", x), format = "%d-%b-%Y")
}

df <- df %>% mutate_at(.funs = funs(convert_date), .vars = chr_to_date_vars)
```
convert character to numeric

```{r}
chr_to_num_vars <- 
  c("annual_inc_joint", "mths_since_last_major_derog", "open_acc_6m",
    "open_il_6m", "open_il_12m", "open_il_24m", "mths_since_rcnt_il",
    "total_bal_il", "il_util", "open_rv_12m", "open_rv_24m",
    "max_bal_bc", "all_util", "total_rev_hi_lim", "total_cu_tl",
    "inq_last_12m", "dti_joint", "inq_fi", "tot_cur_bal", "tot_coll_amt", "int_rate")

df <- df %>%  mutate_at(.funs = funs(as.numeric), .vars = chr_to_num_vars)
```

output a table with amount of unique, N/A, and zero values
```{r}
meta_df %>% select(variable, p_zeros, p_na, unique) %>% knitr::kable()
```

recreate meta table
```{r}
meta_df <- funModeling::df_status( df, print_results = FALSE )
```

set vars from N/A to zero
```{r}
na_to_zero_vars <- c("mths_since_last_delinq", "mths_since_last_record", "mths_since_last_major_derog")

df <- df %>% mutate_at(.vars = na_to_zero_vars, .funs = funs(replace(., is.na(.), 0)))
```

remove columns deemed unfit for modeling. All columns with more than 70% missing values are deemed to be unhelpful in modelling and exploration.
```{r}
vars_to_remove <- c("annual_inc_joint", "dti_joint", "policy_code", "id", "member_id",
                    "emp_title", "url", "desc", "title", "open_acc_6m", "open_il_6m", 
                    "open_il_12m", "open_il_24m", "mths_since_rcnt_il", "total_bal_il", 
                    "il_util", "open_rv_12m", "open_rv_24m", "max_bal_bc", "all_util",
                    "total_rev_hi_lim", "inq_fi", "total_cu_tl", "inq_last_12m",
                    "verification_status_joint", "next_pymnt_d", "sub_grade", "X", "zip_code", "application_type")

df_clean <- df %>% select(-one_of(vars_to_remove))
```

Convert "term" column to number
```{r}
df_clean$term <- as.numeric(gsub( ".*([0-9]+).*", "\\1", df_clean$term ))
```

Convert "emp_length" to numeric values
```{r}
df_clean$emp_length[df_clean$emp_length == "n/a"] <- 99
df_clean$emp_length[df_clean$emp_length == "< 1 year"] <- 0
df_clean$emp_length <- as.numeric(gsub( "([0-9]+).*", "\\1", df_clean$emp_length ))
```

set the training and test data (80% train, 20% test)
```{r}
train_index <- caret::createDataPartition(y = df_clean$int_rate, times = 1, p = .8, list = FALSE)

train <- df_clean[train_index, ]
test <- df_clean[-train_index, ]
```

Output numerical vars
```{r}
num_vars <- 
  train %>% 
  sapply(is.numeric) %>% 
  which() %>% 
  names()

meta_train <- funModeling::df_status(train, print_results = FALSE)

meta_train %>%
  select(variable, p_zeros, p_na, unique) %>%
  filter_(~ variable %in% num_vars) %>%
  knitr::kable()

```

Correlation plot. First step to get an overview of potential collinearities. Failing to identify multicollinearity could result in misleading interpretations of the results.
```{r}
library(corrplot)
corrplot::corrplot(cor(train[, ..num_vars], use = "complete.obs"), 
                   method = "pie", type = "upper",tl.cex = 0.65)
```
Display highly correlated variables. We want to identify collinearities which could affect our regression model. A Cut-off at 0.5 is applied.

```{r}
caret::findCorrelation(cor(train[, ..num_vars], use = "complete.obs"), 
                       names = TRUE, cutoff = .5)
```

Remove highly correlated variables to avoid the interference of collinearity in our model.  Multicollinearity arises when at least two highly correlated predictors are assessed simultaneously in a regression model.
```{r}
vars_to_remove <- 
  c("loan_amnt", "funded_amnt", "funded_amnt_inv", "installment", "total_pymnt_inv", 
    "out_prncp", "collection_recovery_fee", "total_pymnt", "total_rec_prncp", "out_prncp", "total_acc",
    "mths_since_last_record",  "mths_since_last_major_derog", "recoveries")

train <- train %>% select(-one_of(vars_to_remove))

```

Set proper names for variables
```{r}
vars_to_mutate <-
  train %>%
  select(which(sapply(.,is.character))) %>%
  names()

vars_to_mutate

test <-
  test %>%
  mutate_at(.funs = make.names, .vars = vars_to_mutate)
```

Assignment 1: Regression Model for predicting int_rate.

use caret library
```{r}
library(caret)
```

Remove near-zero variance predictors. These predictors can interfere with our model training using cross-validations. We want to remove variables with a high frequency ratio and a high percentage of unique values.
```{r}
nzv <- nearZeroVar(train)
train_filtered <- select(train, -nzv)

glimpse(train_filtered)
```

Define the resampling method for model training. We will apply a 10-time cross validation for our regression models. 
```{r}

fitControl <- trainControl(## 10-fold CV
                           method = "cv",
                           number = 10)
```

Train multiple linear regression model with cross-validation
```{r}


model_lm <- train(int_rate ~ ., data = train_filtered, 
                 method = "lm",
                 trControl = fitControl,
                 na.action=na.exclude)

class(model_lm)

summary (model_lm)
```
Train multiple linear regression model with lasso cross-validation
```{r}
model_lm_lasso <- train(int_rate ~ ., data = train_filtered, 
                 method = "lasso",
                 trControl = fitControl,
                 na.action=na.exclude)

class(model_lm_lasso)

summary (model_lm_lasso)
```


```{r}
model_lm_pred_1 <- 
  predict.lm(object = model_lm, newdata = test, type = "response")
model_pred_t <- function(pred, t) ifelse(pred > t, TRUE, FALSE)
caret::confusionMatrix(data = model_pred_t(model_lm, 0.5), 
                       reference = test$default,
                       positive = "TRUE")
```



Interpret Model performance using ROC
```{r}
library(pROC)

roc_model_lm <- pROC::roc(response = test$int_rate, predictor = model_lm)
roc_model_lm

pROC::plot.roc(x = roc_model_lm, legacy.axes = FALSE, xlim = c(1, 0), asp = NA,
               col = "green", print.auc = FALSE, print.auc.y = .4)

legend(x = "bottomright", col = c("green"), lty = 1, cex = 1.0)
```


Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.
